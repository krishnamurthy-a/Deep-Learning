{"nbformat_minor": 1, "cells": [{"source": "# Image Classification of Handwritten Numeric Digits using TensorFlow", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "In this notebook, we create a artificial neural network model to predict the number that is present in an image that contains the number written in free hand. Here we use Convolutional Neural Network architecture to train the images. The images used for trained are from MNIST dataset. \n\nThe MNIST dataset comprises 60,000 training examples and 10,000 test examples of the handwritten digits 0\u20139, formatted as 28x28-pixel monochrome images.\n", "cell_type": "markdown", "metadata": {}}, {"source": "![MNIST Data set](https://blog.webkid.io/content/images/old/datasets-for-machine-learning/mnist.png)", "cell_type": "markdown", "metadata": {}}, {"source": "", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "### Import the tensorflow library", "cell_type": "markdown", "metadata": {}}, {"source": "import tensorflow as tf", "cell_type": "code", "execution_count": 5, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"}], "metadata": {}}, {"source": "### Import training data", "cell_type": "markdown", "metadata": {}}, {"source": "MNIST data can be downloaded using \"mnist\" module in ", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "from tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)", "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Extracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"}], "metadata": {}}, {"source": "### Neural Network Layout of the model", "cell_type": "markdown", "metadata": {}}, {"source": "![Neural Network for the model](http://solarisailab.com/wp-content/uploads/2017/05/CNNs_For_MNIST.png)", "cell_type": "markdown", "metadata": {}}, {"source": "Ref.: http://solarisailab.com/wp-content/uploads/2017/05/CNNs_For_MNIST.png", "cell_type": "markdown", "metadata": {}}, {"source": "### Configure parameters", "cell_type": "markdown", "metadata": {}}, {"source": "# Network Parameters\nn_input = 784 \nn_classes = 10 \ndropout = 0.75 ", "cell_type": "code", "execution_count": 9, "outputs": [], "metadata": {}}, {"source": "### Define Input variables", "cell_type": "markdown", "metadata": {}}, {"source": "# tf Graph input\nx = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\ny = tf.placeholder(tf.float32, [None, n_classes])", "cell_type": "code", "execution_count": 10, "outputs": [], "metadata": {}}, {"source": "### Define Weights and biases", "cell_type": "markdown", "metadata": {}}, {"source": "# Store layers weight & bias\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n    # 1024 inputs, 10 outputs (class prediction)\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}", "cell_type": "code", "execution_count": 11, "outputs": [], "metadata": {}}, {"source": "### Model Definition - Building the Neural Network", "cell_type": "markdown", "metadata": {}}, {"source": "# Reshape input picture\nx_trans1 = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n# Convolution Layer -1\nx_conv2d_l1 = tf.nn.conv2d(x_trans1, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\nx_w_bias_l1 = tf.nn.bias_add(x_conv2d_l1, biases['bc1'])\nx_relu_l1 = tf.nn.relu(x_w_bias_l1)\nconv1_out = tf.nn.max_pool(x_relu_l1,\n                           ksize=[1, 2, 2, 1],\n                           strides=[1, 2, 2, 1],\n                           padding='SAME')\n\n\n# Convolution Layer -2\nx_conv2d_l2 = tf.nn.conv2d(conv1_out, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\nx_w_bias_l2 = tf.nn.bias_add(x_conv2d_l2, biases['bc2'])\nx_relu_l2 = tf.nn.relu(x_w_bias_l2)\nconv2_out = tf.nn.max_pool(x_relu_l2,\n                           ksize=[1, 2, 2, 1],\n                           strides=[1, 2, 2, 1],\n                           padding='SAME')\n\n# Fully connected layer\n# Reshape conv2 output to fit fully connected layer input\nfc1 = tf.reshape(conv2_out, [-1, weights['wd1'].get_shape().as_list()[0]])\nfc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\nfc1 = tf.nn.relu(fc1)\n\n# Apply Dropout\nfc1 = tf.nn.dropout(fc1, dropout)\n\n# Output, class prediction\nconv_out = tf.add(tf.matmul(fc1, weights['out']), biases['out'], name=\"output_tensor\")\n\npredictor = tf.argmax(conv_out, 1, name=\"predictor\")\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=conv_out, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# To Evaluate model\ncorrect_pred = tf.equal(tf.argmax(conv_out, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n\n", "cell_type": "code", "execution_count": 12, "outputs": [{"output_type": "stream", "name": "stdout", "text": "WARNING:tensorflow:From <ipython-input-12-4bd8bda7f61a>:38: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee tf.nn.softmax_cross_entropy_with_logits_v2.\n\n"}], "metadata": {}}, {"source": "# Training Parameters\nlearning_rate = 0.001\ntraining_iters = 10000 \nbatch_size = 128\ndisplay_step = 10\n", "cell_type": "code", "execution_count": 23, "outputs": [], "metadata": {}}, {"source": "### Start Training Process", "cell_type": "markdown", "metadata": {}}, {"source": "# Initializing the variables\ninit = tf.global_variables_initializer()\n\n# Launch the graph\nsess = tf.Session()\nsess.run(init)\nstep = 1\n\n# Keep training until reach max iterations\nwhile step * batch_size < training_iters:\n    batch_x, batch_y = mnist.train.next_batch(batch_size)\n    # Run optimization op (backprop)\n    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n                                   keep_prob: dropout})\n    print(\"Completed batch iteration: \" + str(step*batch_size) )\n    if step % display_step == 0:\n        # Calculate batch loss and accuracy\n        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n                                                          y: batch_y,\n                                                          keep_prob: 1.})\n    \n        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n              \"{:.5f}\".format(acc))\n    step += 1\nprint(\"Model training finished!\")", "cell_type": "code", "execution_count": 24, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Completed batch iteration: 128\nCompleted batch iteration: 256\nCompleted batch iteration: 384\nCompleted batch iteration: 512\nCompleted batch iteration: 640\nCompleted batch iteration: 768\nCompleted batch iteration: 896\nCompleted batch iteration: 1024\nCompleted batch iteration: 1152\nCompleted batch iteration: 1280\nIter 1280, Minibatch Loss= 39728.546875, Training Accuracy= 0.15625\nCompleted batch iteration: 1408\nCompleted batch iteration: 1536\nCompleted batch iteration: 1664\nCompleted batch iteration: 1792\nCompleted batch iteration: 1920\nCompleted batch iteration: 2048\nCompleted batch iteration: 2176\nCompleted batch iteration: 2304\nCompleted batch iteration: 2432\nCompleted batch iteration: 2560\nIter 2560, Minibatch Loss= 23263.097656, Training Accuracy= 0.29688\nCompleted batch iteration: 2688\nCompleted batch iteration: 2816\nCompleted batch iteration: 2944\nCompleted batch iteration: 3072\nCompleted batch iteration: 3200\nCompleted batch iteration: 3328\nCompleted batch iteration: 3456\nCompleted batch iteration: 3584\nCompleted batch iteration: 3712\nCompleted batch iteration: 3840\nIter 3840, Minibatch Loss= 20982.007812, Training Accuracy= 0.32812\nCompleted batch iteration: 3968\nCompleted batch iteration: 4096\nCompleted batch iteration: 4224\nCompleted batch iteration: 4352\nCompleted batch iteration: 4480\nCompleted batch iteration: 4608\nCompleted batch iteration: 4736\nCompleted batch iteration: 4864\nCompleted batch iteration: 4992\nCompleted batch iteration: 5120\nIter 5120, Minibatch Loss= 12973.332031, Training Accuracy= 0.56250\nCompleted batch iteration: 5248\nCompleted batch iteration: 5376\nCompleted batch iteration: 5504\nCompleted batch iteration: 5632\nCompleted batch iteration: 5760\nCompleted batch iteration: 5888\nCompleted batch iteration: 6016\nCompleted batch iteration: 6144\nCompleted batch iteration: 6272\nCompleted batch iteration: 6400\nIter 6400, Minibatch Loss= 10368.626953, Training Accuracy= 0.60156\nCompleted batch iteration: 6528\nCompleted batch iteration: 6656\nCompleted batch iteration: 6784\nCompleted batch iteration: 6912\nCompleted batch iteration: 7040\nCompleted batch iteration: 7168\nCompleted batch iteration: 7296\nCompleted batch iteration: 7424\nCompleted batch iteration: 7552\nCompleted batch iteration: 7680\nIter 7680, Minibatch Loss= 6784.497070, Training Accuracy= 0.64062\nCompleted batch iteration: 7808\nCompleted batch iteration: 7936\nCompleted batch iteration: 8064\nCompleted batch iteration: 8192\nCompleted batch iteration: 8320\nCompleted batch iteration: 8448\nCompleted batch iteration: 8576\nCompleted batch iteration: 8704\nCompleted batch iteration: 8832\nCompleted batch iteration: 8960\nIter 8960, Minibatch Loss= 8179.582031, Training Accuracy= 0.64844\nCompleted batch iteration: 9088\nCompleted batch iteration: 9216\nCompleted batch iteration: 9344\nCompleted batch iteration: 9472\nCompleted batch iteration: 9600\nCompleted batch iteration: 9728\nCompleted batch iteration: 9856\nCompleted batch iteration: 9984\nModel training finished!\n"}], "metadata": {}}, {"source": "# Calculate accuracy for 256 mnist test images\nprint(\"Testing Accuracy:\", \\\nsess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n                                      y: mnist.test.labels[:256],\n                                      keep_prob: 1.}))", "cell_type": "code", "execution_count": 25, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Testing Accuracy: 0.71484375\n"}], "metadata": {}}, {"source": "Now the model has been trained.", "cell_type": "markdown", "metadata": {}}, {"source": "Let us try to predict using this trained model. ", "cell_type": "markdown", "metadata": {}}, {"source": "### Prediction", "cell_type": "markdown", "metadata": {}}, {"source": "Let us choose a couple of images to predict from the MNIST dataset", "cell_type": "markdown", "metadata": {}}, {"source": "image1 = mnist.test.images[45,]\nimage2 = mnist.test.images[4,].tolist()", "cell_type": "code", "execution_count": 20, "outputs": [], "metadata": {}}, {"source": "Display the image that we want to classify", "cell_type": "markdown", "metadata": {}}, {"source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np", "cell_type": "code", "execution_count": 18, "outputs": [], "metadata": {}}, {"source": "for i, image in enumerate([image1, image2]):\n    plt.subplot(2, 2, i + 1)\n    plt.axis('off')\n    plt.imshow( (np.reshape(image, (28, 28)) * 255).astype(np.uint8), cmap=plt.cm.gray_r, interpolation='nearest')", "cell_type": "code", "execution_count": 21, "outputs": [{"output_type": "display_data", "data": {"image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAACFCAYAAADCQpQyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAB1dJREFUeJzt3U+IzV0cx/Ezejb+lWQmG5Qsxr8if1IMmo0iCzPKSJIFC2nERv4k+TOTjcKCyG4WQkYSshFKNlggNspMSiFlMSJqns085/l+z3PvNXOf+/vNvffzfq2+p3Ob32m6Pn6/M+d3TsPg4GAAACVjRnsAAJA3gg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgJy/cr4er4lUj4bRHkAd4XtdPYb1veaOD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AnLx3YK4JW7dude3+/v5Yz5492/WtWLHCtdP+4ZoyZUqsZ8yYUdbPAJ4/f+7abW1tsX7//n3m179//75r238P06ZNy/z6w8UdHwA5BB8AOQ2Dg7mek1K1h7J8/vw51kuXLnV9fX19sW5o8GeZpL8/2z+SvpUrV8a6s7PT9dnHlQrisKHKqZrvdXd3t2ufPXs21h8/fsz8+rt373btL1++xPrKlSuZXz9w2BAAFEbwAZBD8AGQw3KWIXbJip3TCyGECxcuxHrnzp2uz84NhhBCb29vrJubm13f27dvi17f/tm/q6vL9c2ZM6fozwR+//4d6zt37oziSEJYvHixa58+fTrWAwMDrm/8+PG5jKkQ7vgAyCH4AMjhUbeAdMlKKY2Nja6dPgpbdslKKQcPHnRtHm9RyoMHD2L95MkT17d///5cx/L161fXfv36day/f//u+njUBYAcEXwA5BB8AOQwx1dAzq/x/UdLS8uoXh/V7eXLl67d0dER61mzZrm+dL44a7du3cr1euXijg+AHIIPgBwedYe8efMm1iNZzgLk7eTJk65tl4n09PS4vgkTJmQ+HruE5eHDh66vWv8tcccHQA7BB0AOwQdADnN8Q27cuBHr0V7OAqSuX78e63QHFruEZcmSJbmN6R8nTpyIdTqnt3r16lhPmjQpryH9EXd8AOQQfADkcNjQkDFj/v0/IL1dnz59eqzt+bd/cuDAAdfO6NCgclXnOoPalPn3etOmTbG2j70hhHDu3LlY79q1K+uh/Od83mXLlsU63Z3l3r17sW5tbc10XEM4bAgACiH4AMgh+ADIkV3OYv8EH0LpJSwjmQe1Byi3t7e7PjvfsWbNmmH/TOj59u2baz99+rToZ/OY17MuXrzo2vbALXswVgi5zeuNGHd8AOQQfADkSD3q2h1YTp065frsEpbDhw+7vs7Ozlj/aTmLfdRtampyfdu2bYu1PSAmBH+uLvDz50/X/vDhQ6w3b96c93Ccd+/eFe2bN29ejiMpH3d8AOQQfADkEHwA5EjN8Z05cybWAwMDrs8uLzl27FjZ17BzgOlBL11dXbF+/Pix62OOD9bEiRNde8GCBbFODxuyr4lNnjw5k/F8+vQp1teuXSv6ueXLl2dy/Urjjg+AHIIPgByCD4AcqTm+HTt2xDrdeur48eMVv96GDRtcu7u7u+LXQH0aO3asa9tdltNtqdatWxfrffv2lXW9V69euXa6Vq+vry/WpU5Os9u7VbPaGCUAVBDBB0CO1KOu3Un5/PnzmV/v0aNHrs0hRijX0aNHY51+j27fvh3rjo6Osn5+Y2Oja6ePs/ZVzFK2b99e1vXzxh0fADkEHwA5BB8AOXU9x2cPCQ8hhEuXLsX67t27mV//5s2brl1qGQBQin2l8erVq67vxYsXsS61ZVQpGzduLNlvt1Tr6ekp+rl0GU614o4PgByCD4Ccun7UTd+UGMlh4OWyB6+ky1nso25LS0vmY4GGhQsXFqwraebMmcP6XLpzzPz587MYzv/GHR8AOQQfADkEHwA5dTfHZ+fY0tds7O4sWVwvhBDWrl0b63T5ij29jR2XUUvsa3KlXr2s1jm9FHd8AOQQfADk1N2jrt1lIj14xR6YUi57KHkIIRw6dMi1nz17FutFixa5PnswOVBL7LRNPbyBxB0fADkEHwA5BB8AOXU3x2fNnTvXtS9fvhzrpqYm12cPBurt7XV99vDvdMeV9GDy9vb2WKe7POfxyhyQhR8/fhTtq5UdWSzu+ADIIfgAyGnI+QCcXC+WLj1ZtWpVrNO3OuzvIf1zve1ra2tzfVu2bHHttL+K1f6ahOpR96dITZ06Nda/fv1yfUeOHIn1nj17chtTEcP6XnPHB0AOwQdADsEHQE5dz/Gl+vv7Y20PHgrBL1mxS1tC8LslNzc3u75x48ZVcoh5Yo6vcup+jm/9+vWx3rt3r+trbW3NezilMMcHAIUQfADkSD3qwuFRt3L4XlcPHnUBoBCCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgJy8DxviNSnUI77XNYY7PgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acgg+AHIIPgByCD4Acv4GjwiVa/SFHYsAAAAASUVORK5CYII=\n", "text/plain": "<matplotlib.figure.Figure at 0x7f4130b5b2e8>"}, "metadata": {}}], "metadata": {}}, {"source": "Let us now use Tensorflow API to predict the numbers in these images", "cell_type": "markdown", "metadata": {}}, {"source": "prediction = sess.run(predictor, feed_dict={x:[image1, image2], keep_prob: 1.})\nprint(sgl_predict)", "cell_type": "code", "execution_count": 29, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[5 4]\n"}], "metadata": {}}, {"source": "The output above contains the numbers that is written in the images that were used for prediction. The matching of prediction result with the actual numbers in the image will vary based on the accuracy of the images.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.0 (Deprecated)", "name": "python3-spark20", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}}